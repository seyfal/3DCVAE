{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;20mWARNING | Hyperspy | `signal_type='EELS'` not understood. See `hs.print_known_signal_types()` for a list of installed signal types or https://github.com/hyperspy/hyperspy-extensions-list for the list of all hyperspy extensions providing signals. (hyperspy.io:744)\u001b[0m\n",
      "\u001b[33;20mWARNING | Hyperspy | `signal_type='EELS'` not understood. See `hs.print_known_signal_types()` for a list of installed signal types or https://github.com/hyperspy/hyperspy-extensions-list for the list of all hyperspy extensions providing signals. (hyperspy.io:744)\u001b[0m\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DAGMM(nn.Module):\n",
    "    def __init__(self, n_gmm=2, z_dim=128):\n",
    "        super(DAGMM, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(1,1,7), stride=(1,1,2), padding=(0,0,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=(3,3,5), stride=(1,1,2), padding=(1,1,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 256, kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 6 * 6 * 30, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, z_dim)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256 * 6 * 6 * 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (256, 6, 6, 30)),\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1), output_padding=(1,1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1), output_padding=(1,1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=(3,3,5), stride=(1,1,2), padding=(1,1,2), output_padding=(0,0,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(32, 1, kernel_size=(1,1,7), stride=(1,1,2), padding=(0,0,3), output_padding=(0,0,1))\n",
    "        )\n",
    "        \n",
    "        # Estimation network\n",
    "        self.estimation = nn.Sequential(\n",
    "            nn.Linear(z_dim + 2, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(10, n_gmm),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def estimate(self, z):\n",
    "        return self.estimation(z)\n",
    "\n",
    "    def compute_reconstruction(self, x, x_hat):\n",
    "        relative_euclidean_distance = (x - x_hat).norm(2, dim=(1,2,3,4)) / x.norm(2, dim=(1,2,3,4))\n",
    "        cosine_similarity = F.cosine_similarity(x.view(x.size(0), -1), x_hat.view(x_hat.size(0), -1), dim=1)\n",
    "        return relative_euclidean_distance, cosine_similarity\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_c = self.encode(x)\n",
    "        x_hat = self.decode(z_c)\n",
    "        rec_1, rec_2 = self.compute_reconstruction(x, x_hat)\n",
    "        z = torch.cat([z_c, rec_1.unsqueeze(-1), rec_2.unsqueeze(-1)], dim=1)\n",
    "        gamma = self.estimate(z)\n",
    "        return z_c, x_hat, z, gamma\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class ComputeLoss:\n",
    "    def __init__(self, model, lambda_energy, lambda_cov, device, n_gmm):\n",
    "        self.model = model\n",
    "        self.lambda_energy = lambda_energy\n",
    "        self.lambda_cov = lambda_cov\n",
    "        self.device = device\n",
    "        self.n_gmm = n_gmm\n",
    "\n",
    "    def forward(self, x, x_hat, z, gamma):\n",
    "        \"\"\"Computing the loss function for DAGMM.\"\"\"\n",
    "        reconst_loss = torch.mean((x-x_hat).pow(2))\n",
    "        sample_energy, cov_diag = self.compute_energy(z, gamma, sample_mean=True)\n",
    "        loss = reconst_loss + self.lambda_energy * sample_energy + self.lambda_cov * cov_diag\n",
    "        return loss\n",
    "\n",
    "    def compute_energy(self, z, gamma, phi=None, mu=None, cov=None, sample_mean=False):\n",
    "        \"\"\"Computing the sample energy function\"\"\"\n",
    "        if (phi is None) or (mu is None) or (cov is None):\n",
    "            phi, mu, cov = self.compute_params(z, gamma)\n",
    "        \n",
    "        z_mu = (z.unsqueeze(1)- mu.unsqueeze(0))\n",
    "        \n",
    "        eps = 1e-12\n",
    "        cov_inverse = []\n",
    "        det_cov = []\n",
    "        cov_diag = 0\n",
    "        \n",
    "        for k in range(self.n_gmm):\n",
    "            cov_k = cov[k] + torch.eye(cov[k].size(-1)).to(self.device) * eps\n",
    "            cov_inverse.append(torch.inverse(cov_k).unsqueeze(0))\n",
    "            det_cov.append(torch.logdet(cov_k * (2*np.pi)).unsqueeze(0))\n",
    "            cov_diag += torch.sum(1 / cov_k.diag())\n",
    "        \n",
    "        cov_inverse = torch.cat(cov_inverse, dim=0)\n",
    "        det_cov = torch.cat(det_cov).to(self.device)\n",
    "        \n",
    "        E_z = -0.5 * torch.sum(torch.sum(z_mu.unsqueeze(-1) * cov_inverse.unsqueeze(0), dim=-2) * z_mu, dim=-1)\n",
    "        E_z = E_z - 0.5 * det_cov.unsqueeze(0)\n",
    "        E_z = -torch.logsumexp(torch.log(phi.unsqueeze(0)) + E_z, dim=1)\n",
    "        \n",
    "        if sample_mean:\n",
    "            E_z = torch.mean(E_z)\n",
    "        \n",
    "        return E_z, cov_diag\n",
    "\n",
    "    def compute_params(self, z, gamma):\n",
    "        \"\"\"Computing the parameters phi, mu and gamma for sample energy function \"\"\" \n",
    "        phi = torch.sum(gamma, dim=0) / gamma.size(0) \n",
    "        mu = torch.sum(z.unsqueeze(1) * gamma.unsqueeze(-1), dim=0)\n",
    "        mu /= torch.sum(gamma, dim=0).unsqueeze(-1)\n",
    "        z_mu = (z.unsqueeze(1) - mu.unsqueeze(0))\n",
    "        z_mu_z_mu_t = z_mu.unsqueeze(-1) * z_mu.unsqueeze(-2)\n",
    "        cov = torch.sum(gamma.unsqueeze(-1).unsqueeze(-1) * z_mu_z_mu_t, dim=0)\n",
    "        cov /= torch.sum(gamma, dim=0).unsqueeze(-1).unsqueeze(-1)\n",
    "        return phi, mu, cov\n",
    "    \n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import numpy as np\n",
    "from barbar import Bar\n",
    "\n",
    "# def weights_init_normal(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find(\"Conv\") != -1 and classname != 'Conv':\n",
    "#         torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "#         torch.nn.init.normal_(m.bias.data, 0.0, 0.02)\n",
    "#     elif classname.find(\"Linear\") != -1:\n",
    "#         torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "#         torch.nn.init.normal_(m.bias.data, 0.0, 0.02)\n",
    "#     elif classname.find('BatchNorm') != -1:\n",
    "#         m.weight.data.normal_(1.0, 0.01)\n",
    "#         m.bias.data.fill_(0)\n",
    "        \n",
    "def weights_init_normal(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def inject_anomalies(image, num_clusters=1, cluster_size=5, shift_amount=40, noise_factor=0.1, peak_reduction_factor=0.2, peak_reduction_probability=0.3):\n",
    "    \"\"\"\n",
    "    Inject anomalies into the EELS image with added noise and peak reduction options.\n",
    "    \n",
    "    Args:\n",
    "    image (numpy.ndarray): Input image of shape (height, width, energy_channels)\n",
    "    num_clusters (int): Number of anomalous clusters to inject\n",
    "    cluster_size (int): Size of each anomalous cluster\n",
    "    shift_amount (int): Amount to shift the peak (in energy channels)\n",
    "    noise_factor (float): Factor to control the amount of noise added (0 to 1)\n",
    "    peak_reduction_factor (float): Factor to reduce peak intensity (0 to 1)\n",
    "    peak_reduction_probability (float): Probability of applying peak reduction to a cluster (0 to 1)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (anomalous_image, anomaly_mask)\n",
    "        anomalous_image (numpy.ndarray): Image with injected anomalies, noise, and peak reductions\n",
    "        anomaly_mask (numpy.ndarray): Boolean mask indicating anomalous pixels\n",
    "    \"\"\"\n",
    "    anomalous_image = np.copy(image)\n",
    "    height, width, channels = image.shape\n",
    "    anomaly_mask = np.zeros((height, width), dtype=bool)\n",
    "    \n",
    "    # Add global noise\n",
    "    noise = np.random.normal(0, noise_factor * np.mean(image), image.shape)\n",
    "    anomalous_image += noise\n",
    "    \n",
    "    for _ in range(num_clusters):\n",
    "        # Choose a random center for the cluster\n",
    "        center_y = np.random.randint(cluster_size, height - cluster_size)\n",
    "        center_x = np.random.randint(cluster_size, width - cluster_size)\n",
    "        \n",
    "        # Define the cluster region\n",
    "        y_start, y_end = center_y - cluster_size // 2, center_y + cluster_size // 2 + 1\n",
    "        x_start, x_end = center_x - cluster_size // 2, center_x + cluster_size // 2 + 1\n",
    "        \n",
    "        # Mark the cluster region as anomalous\n",
    "        anomaly_mask[y_start:y_end, x_start:x_end] = True\n",
    "        \n",
    "        # Shift the peak\n",
    "        if np.random.random() < 0.5:  # 50% chance to shift left or right\n",
    "            anomalous_image[y_start:y_end, x_start:x_end, :-shift_amount] = image[y_start:y_end, x_start:x_end, shift_amount:]\n",
    "        else:\n",
    "            anomalous_image[y_start:y_end, x_start:x_end, shift_amount:] = image[y_start:y_end, x_start:x_end, :-shift_amount]\n",
    "        \n",
    "        # Randomly reduce peak intensity\n",
    "        if np.random.random() < peak_reduction_probability:\n",
    "            peak_intensity = np.max(anomalous_image[y_start:y_end, x_start:x_end])\n",
    "            reduction_amount = peak_intensity * peak_reduction_factor\n",
    "            anomalous_image[y_start:y_end, x_start:x_end] -= reduction_amount\n",
    "    \n",
    "    # Ensure all values are non-negative\n",
    "    anomalous_image = np.clip(anomalous_image, 0, None)\n",
    "    \n",
    "    return anomalous_image, anomaly_mask\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf, accuracy_score\n",
    "from anomaly_detection.config.config_handler import get_config\n",
    "\n",
    "class TrainerDAGMM:\n",
    "    def __init__(self, config, train_loader, test_loader, device):\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = DAGMM(n_gmm=config['n_gmm'], z_dim=config['latent_dim']).to(device)\n",
    "        self.model.apply(weights_init_normal)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=float(config['learning_rate']))\n",
    "        \n",
    "        # Initialize loss computer\n",
    "        self.compute_loss = ComputeLoss(self.model, config['lambda_energy'], config['lambda_cov'], \n",
    "                                        self.device, config['n_gmm'])\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        for epoch in range(self.config['epochs']):\n",
    "            total_loss = 0\n",
    "            for batch in self.train_loader:\n",
    "                x = batch.float().to(self.device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                _, x_hat, z, gamma = self.model(x)\n",
    "                loss = self.compute_loss.forward(x, x_hat, z, gamma)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5)\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            avg_loss = total_loss / len(self.train_loader)\n",
    "            print(f'Epoch [{epoch+1}/{self.config['epochs']}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "            # Test on training data every few epochs\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                self.test_on_train()\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        for epoch in range(self.config['epochs']):\n",
    "            total_loss = 0\n",
    "            for batch, _ in self.train_loader:  # Ignore the labels during training\n",
    "                x = batch.to(self.device)  # batch is already a float tensor\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                _, x_hat, z, gamma = self.model(x)\n",
    "                loss = self.compute_loss.forward(x, x_hat, z, gamma)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5)\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            avg_loss = total_loss / len(self.train_loader)\n",
    "            print(f'Epoch [{epoch+1}/{self.config['epochs']}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Evaluating the DAGMM model\"\"\"\n",
    "        self.model.eval()\n",
    "        print('Evaluating...')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            N_samples = 0\n",
    "            gamma_sum = 0\n",
    "            mu_sum = 0\n",
    "            cov_sum = 0\n",
    "            \n",
    "            # Obtaining the parameters gamma, mu and cov using the training (clean) data.\n",
    "            for x, _ in self.train_loader:\n",
    "                x = x.float().to(self.device)\n",
    "                _, _, z, gamma = self.model(x)\n",
    "                phi_batch, mu_batch, cov_batch = self.compute_loss.compute_params(z, gamma)\n",
    "                batch_gamma_sum = torch.sum(gamma, dim=0)\n",
    "                gamma_sum += batch_gamma_sum\n",
    "                mu_sum += mu_batch * batch_gamma_sum.unsqueeze(-1)\n",
    "                cov_sum += cov_batch * batch_gamma_sum.unsqueeze(-1).unsqueeze(-1)\n",
    "                \n",
    "                N_samples += x.size(0)\n",
    "            \n",
    "            train_phi = gamma_sum / N_samples\n",
    "            train_mu = mu_sum / gamma_sum.unsqueeze(-1)\n",
    "            train_cov = cov_sum / gamma_sum.unsqueeze(-1).unsqueeze(-1)\n",
    "            \n",
    "            # Obtaining Labels and energy scores for train data\n",
    "            energy_train = []\n",
    "            labels_train = []\n",
    "            for x, y in self.train_loader:\n",
    "                x = x.float().to(self.device)\n",
    "                _, _, z, gamma = self.model(x)\n",
    "                sample_energy, _  = self.compute_loss.compute_energy(z, gamma, phi=train_phi,\n",
    "                                                                     mu=train_mu, cov=train_cov, \n",
    "                                                                     sample_mean=False)\n",
    "                \n",
    "                energy_train.append(sample_energy.detach().cpu())\n",
    "                labels_train.append(y)\n",
    "            energy_train = torch.cat(energy_train).numpy()\n",
    "            labels_train = torch.cat(labels_train).numpy()\n",
    "            \n",
    "            # Obtaining Labels and energy scores for test data\n",
    "            energy_test = []\n",
    "            labels_test = []\n",
    "            for x, y in self.test_loader:\n",
    "                x = x.float().to(self.device)\n",
    "                _, _, z, gamma = self.model(x)\n",
    "                sample_energy, _  = self.compute_loss.compute_energy(z, gamma, train_phi,\n",
    "                                                                     train_mu, train_cov,\n",
    "                                                                     sample_mean=False)\n",
    "                \n",
    "                energy_test.append(sample_energy.detach().cpu())\n",
    "                labels_test.append(y)\n",
    "            energy_test = torch.cat(energy_test).numpy()\n",
    "            labels_test = torch.cat(labels_test).numpy()\n",
    "        \n",
    "        scores_total = np.concatenate((energy_train, energy_test), axis=0)\n",
    "        labels_total = np.concatenate((labels_train, labels_test), axis=0)\n",
    "        \n",
    "        threshold = np.percentile(scores_total, 100 - 20)\n",
    "        pred = (energy_test > threshold).astype(int)\n",
    "        gt = labels_test.astype(int)\n",
    "        precision, recall, f_score, _ = prf(gt, pred, average='binary')\n",
    "        print(\"Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f}\".format(precision, recall, f_score))\n",
    "        print('ROC AUC score: {:.2f}'.format(roc_auc_score(labels_total, scores_total)*100))\n",
    "        \n",
    "        return labels_total, scores_total\n",
    "    \n",
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "from skimage.filters import gaussian\n",
    "from scipy.ndimage import uniform_filter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Load configuration\n",
    "config = get_config(\"/home/ssulta24/Desktop/VCAE_new/anomaly_detection/config/config.yaml\")\n",
    "\n",
    "filepath = config['data_path']\n",
    "energy_range = tuple(config['energy_range'])\n",
    "size = 24\n",
    "sigma = config['sigma']\n",
    "xy_window = 3\n",
    "\n",
    "def load_and_preprocess():\n",
    "    \"\"\"\n",
    "    Load and preprocess the EELS data.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed EELS data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw_data = load_dm_data()\n",
    "        preprocessed_data = preprocess_3d_images(raw_data)\n",
    "        print(\"done\")\n",
    "        return preprocessed_data\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def load_dm_data():\n",
    "    \"\"\"\n",
    "    Load data from a Digital Micrograph file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Raw EELS data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = hs.load(filepath)\n",
    "        data = s.data\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def preprocess_3d_images(image):\n",
    "    \"\"\"\n",
    "    Preprocess the 3D EELS image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Raw 3D EELS image\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed 3D EELS image\n",
    "    \"\"\"\n",
    "    # Apply Gaussian blur\n",
    "    blurred_image = gaussian(image, sigma=sigma, mode='reflect', preserve_range=True)\n",
    "    \n",
    "    # Slice the data array to keep only the desired energy range\n",
    "    start_pixel = int(energy_range[0] - 0)\n",
    "    end_pixel = int(energy_range[1] - 0)\n",
    "    blurred_image = blurred_image[:, :, start_pixel:end_pixel]\n",
    "\n",
    "    # Apply min-max scaling\n",
    "    min_val = np.min(blurred_image)\n",
    "    max_val = np.max(blurred_image)\n",
    "    normalized_image = (blurred_image - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Apply spatial-spectral smoothing\n",
    "    smoothed_img = smooth_spatial_spectral(normalized_image)\n",
    "    \n",
    "    # Generate sub-images using sliding window\n",
    "    sub_images = sliding_window(smoothed_img)\n",
    "    \n",
    "    # Reshape sub-images for PyTorch (batch_size, channels, height, width, energy)\n",
    "    reshaped_sub_images = sub_images.reshape(-1, size, size, sub_images.shape[-1])\n",
    "    \n",
    "    return reshaped_sub_images.astype('float32')\n",
    "\n",
    "def smooth_spatial_spectral(arr):\n",
    "    \"\"\"\n",
    "    Apply spatial-spectral smoothing to the image.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): Input 3D array\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Smoothed 3D array\n",
    "    \"\"\"\n",
    "    neighborhood_sum = uniform_filter(arr, size=(xy_window, xy_window, 1), mode='reflect')\n",
    "    neighborhood_count = uniform_filter(np.ones_like(arr), size=(xy_window, xy_window, 1), mode='reflect')\n",
    "    return neighborhood_sum / neighborhood_count\n",
    "\n",
    "def sliding_window(data, stride=24):\n",
    "    \"\"\"\n",
    "    Generate sub-images using a sliding window approach.\n",
    "    \n",
    "    Args:\n",
    "        data (numpy.ndarray): Input data of shape (height, width, energy)\n",
    "        stride (int): Step size for the sliding window\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Array of sub-images\n",
    "    \"\"\"\n",
    "    height, width, energy = data.shape\n",
    "    sub_images = []\n",
    "    \n",
    "    for i in range(0, height - size + 1, stride):\n",
    "        for j in range(0, width - size + 1, stride):\n",
    "            sub_image = data[i:i+size, j:j+size, :]\n",
    "            sub_images.append(sub_image)\n",
    "    \n",
    "    return np.array(sub_images)\n",
    "\n",
    "data = load_and_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal data shape: (64, 24, 24, 480)\n",
      "Shape of the anom data: (30, 24, 24, 480)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 1, 1, 7], expected input[1, 52, 24, 24, 480] to have 1 channels, but got 52 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m create_train_test_loaders(data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m63\u001b[39m)\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TrainerDAGMM(config, train_loader, test_loader, device)\n\u001b[0;32m---> 45\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     46\u001b[0m labels, scores \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[31], line 270\u001b[0m, in \u001b[0;36mTrainerDAGMM.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m x \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# batch is already a float tensor\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 270\u001b[0m _, x_hat, z, gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m    271\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss\u001b[38;5;241m.\u001b[39mforward(x, x_hat, z, gamma)\n\u001b[1;32m    272\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 65\u001b[0m, in \u001b[0;36mDAGMM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 65\u001b[0m     z_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(x)\n\u001b[1;32m     66\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z_c)\n\u001b[1;32m     67\u001b[0m     rec_1, rec_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_reconstruction(x, x_hat)\n",
      "Cell \u001b[0;32mIn[31], line 51\u001b[0m, in \u001b[0;36mDAGMM.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/conv.py:717\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/torch/nn/modules/conv.py:712\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    702\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    703\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    711\u001b[0m     )\n\u001b[0;32m--> 712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    714\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 1, 1, 7], expected input[1, 52, 24, 24, 480] to have 1 channels, but got 52 channels instead"
     ]
    }
   ],
   "source": [
    "from anomaly_detection.data.data_loader import EELSDataset, get_data_loader\n",
    "\n",
    "# Load configuration\n",
    "config = get_config(\"/home/ssulta24/Desktop/VCAE_new/anomaly_detection/config/config.yaml\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "def create_train_test_loaders(normal_data, batch_size, test_split=0.2, num_anomalies=30):\n",
    "    print(f\"Normal data shape: {normal_data.shape}\")\n",
    "    \n",
    "    # Split normal data into train and test\n",
    "    num_test = int(normal_data.shape[0] * test_split)\n",
    "    train_data = normal_data[:-num_test]\n",
    "    test_normal_data = normal_data[-num_test:]\n",
    "    \n",
    "    # Create anomalous data\n",
    "    anomalous_data = []\n",
    "    for i in range(num_anomalies):\n",
    "        normal_image = test_normal_data[i % len(test_normal_data)]\n",
    "        anomalous_image, _ = inject_anomalies(normal_image)\n",
    "        anomalous_data.append(anomalous_image)\n",
    "    anomalous_data = np.array(anomalous_data)\n",
    "    print(f\"Shape of the anom data: {anomalous_data.shape}\")\n",
    "    \n",
    "    # Create train loader (all normal)\n",
    "    train_dataset = TensorDataset(torch.tensor(train_data).float(), torch.zeros(len(train_data)))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Create test loader (mix of normal and anomalous)\n",
    "    test_data = np.concatenate([test_normal_data, anomalous_data])\n",
    "    test_labels = np.concatenate([np.zeros(len(test_normal_data)), np.ones(len(anomalous_data))])\n",
    "    test_dataset = TensorDataset(torch.tensor(test_data).float(), torch.tensor(test_labels))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Splitgh\n",
    "train_loader, test_loader = create_train_test_loaders(data, batch_size=63)\n",
    "\n",
    "trainer = TrainerDAGMM(config, train_loader, test_loader, device)\n",
    "trainer.train()\n",
    "labels, scores = trainer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
