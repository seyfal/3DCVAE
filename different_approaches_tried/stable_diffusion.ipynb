{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # Convert time to float32\n",
    "        t = t.float().unsqueeze(-1)\n",
    "        return self.layer(t)\n",
    "\n",
    "class EELSDataset(Dataset):\n",
    "    def __init__(self, data, noise_level=0.1, device='cpu'):\n",
    "        # Ensure data is float32\n",
    "        self.data = torch.FloatTensor(data).to(device)\n",
    "        self.noise_level = noise_level\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        spectrum = self.data[idx]\n",
    "        noisy_spectrum = spectrum + torch.randn_like(spectrum) * self.noise_level * torch.std(spectrum)\n",
    "        return noisy_spectrum, spectrum\n",
    "\n",
    "class DiffusionModel:\n",
    "    def __init__(self, model, n_steps=1000, beta_start=1e-4, beta_end=2e-2, device='cpu'):\n",
    "        self.model = model\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        \n",
    "        # Move all tensors to the specified device and ensure float32\n",
    "        self.beta = torch.linspace(beta_start, beta_end, n_steps, dtype=torch.float32).to(device)\n",
    "        self.alpha = (1 - self.beta).to(device)\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0).to(device)\n",
    "        \n",
    "    def diffusion_step(self, x, t):\n",
    "        noise = torch.randn_like(x, device=self.device)\n",
    "        t = t.long()  # Ensure t is long for indexing\n",
    "        alpha_t = self.alpha_bar[t].float().view(-1, 1)  # Convert to float32\n",
    "        return torch.sqrt(alpha_t) * x + torch.sqrt(1 - alpha_t) * noise, noise\n",
    "    \n",
    "    def denoise(self, noisy_data, n_steps=None):\n",
    "        if n_steps is None:\n",
    "            n_steps = self.n_steps\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            x = noisy_data.to(self.device)\n",
    "            for t in range(n_steps - 1, -1, -1):\n",
    "                t_tensor = torch.ones(x.shape[0], device=self.device, dtype=torch.float32) * t\n",
    "                predicted_noise = self.model(x, t_tensor)\n",
    "                alpha_t = self.alpha[t].float()\n",
    "                alpha_bar_t = self.alpha_bar[t].float()\n",
    "                \n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                    \n",
    "                x = (1 / torch.sqrt(alpha_t)) * (\n",
    "                    x - (1 - alpha_t) / torch.sqrt(1 - alpha_bar_t) * predicted_noise\n",
    "                ) + torch.sqrt(1 - alpha_t) * noise\n",
    "                \n",
    "        return x.cpu()\n",
    "\n",
    "class SpectralUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_dims=[16, 32, 64]):\n",
    "        super().__init__()\n",
    "        self.time_embed = TimeEmbedding(hidden_dims[0])\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[0]),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoders = nn.ModuleList()\n",
    "        current_channels = in_channels\n",
    "        for dim in hidden_dims:\n",
    "            self.encoders.append(nn.Sequential(\n",
    "                nn.Conv1d(current_channels, dim, 3, padding='same'),\n",
    "                nn.GroupNorm(8, dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv1d(dim, dim, 3, padding='same'),\n",
    "                nn.GroupNorm(8, dim),\n",
    "                nn.SiLU(),\n",
    "                nn.AvgPool1d(2, padding=0)\n",
    "            ))\n",
    "            current_channels = dim\n",
    "        \n",
    "        # Middle\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv1d(hidden_dims[-1], hidden_dims[-1], 3, padding='same'),\n",
    "            nn.GroupNorm(8, hidden_dims[-1]),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(hidden_dims[-1], hidden_dims[-1], 3, padding='same'),\n",
    "            nn.GroupNorm(8, hidden_dims[-1]),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoders = nn.ModuleList()\n",
    "        hidden_dims_reversed = hidden_dims[::-1]\n",
    "        \n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            in_channels = hidden_dims_reversed[i] + hidden_dims_reversed[i + 1]\n",
    "            out_channels = hidden_dims_reversed[i + 1]\n",
    "            \n",
    "            self.decoders.append(nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 3, padding='same'),\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv1d(out_channels, out_channels, 3, padding='same'),\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.SiLU()\n",
    "            ))\n",
    "        \n",
    "        # Output\n",
    "        self.output = nn.Conv1d(hidden_dims[0], 1, 1)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        # Add channel dimension if needed\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        # Store original size\n",
    "        original_size = x.shape[-1]\n",
    "        \n",
    "        # Time embedding\n",
    "        t_emb = self.time_embed(t)\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "        \n",
    "        # Encoder path with skip connections\n",
    "        skips = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            skips.append(x)\n",
    "        \n",
    "        # Middle\n",
    "        x = self.middle(x)\n",
    "        \n",
    "        # Decoder path\n",
    "        skips = skips[:-1][::-1]  # Remove last skip and reverse\n",
    "        \n",
    "        for skip, decoder in zip(skips, self.decoders):\n",
    "            # Upsample to match skip connection size\n",
    "            x = F.interpolate(x, size=skip.shape[-1], mode='linear', align_corners=False)\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = decoder(x)\n",
    "        \n",
    "        # Final upsampling to original size\n",
    "        x = F.interpolate(x, size=original_size, mode='linear', align_corners=False)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x.squeeze(1)\n",
    "\n",
    "def train_diffusion_model(SI_data, device='cuda'):\n",
    "    # Prepare data\n",
    "    data = SI_data.reshape(-1, SI_data.shape[-1])\n",
    "    \n",
    "    try:\n",
    "        # Create dataset and dataloader\n",
    "        dataset = EELSDataset(data, device=device)\n",
    "        dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = SpectralUNet(\n",
    "            in_channels=1,\n",
    "            hidden_dims=[16, 32, 64]\n",
    "        ).to(device)\n",
    "        \n",
    "        # Initialize diffusion\n",
    "        diffusion = DiffusionModel(model, n_steps=50, device=device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "        \n",
    "        # Training loop\n",
    "        n_epochs = 1\n",
    "        for epoch in range(n_epochs):\n",
    "            total_loss = 0\n",
    "            for noisy, clean in dataloader:\n",
    "                noisy, clean = noisy.float(), clean.float()\n",
    "                t = torch.randint(0, diffusion.n_steps, (clean.shape[0],), device=device)\n",
    "                \n",
    "                x_t, noise = diffusion.diffusion_step(clean, t)\n",
    "                t = t.float()\n",
    "                \n",
    "                predicted_noise = model(x_t, t)\n",
    "                loss = F.mse_loss(predicted_noise, noise)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        return diffusion\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "def denoise_EELS_data(SI_data, diffusion_model=None, device='cuda'):\n",
    "    print(f\"Starting denoising process...\")\n",
    "    \n",
    "    if diffusion_model is None:\n",
    "        print(\"Training new diffusion model...\")\n",
    "        diffusion_model = train_diffusion_model(SI_data, device)\n",
    "    \n",
    "    # Reshape data for processing\n",
    "    original_shape = SI_data.shape\n",
    "    data = SI_data.reshape(-1, original_shape[-1])\n",
    "    \n",
    "    # Process in batches\n",
    "    batch_size = 32\n",
    "    denoised_data = []\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = torch.FloatTensor(data[i:i+batch_size]).to(device)\n",
    "        denoised_batch = diffusion_model.denoise(batch)\n",
    "        denoised_data.append(denoised_batch.cpu().numpy())\n",
    "    \n",
    "    denoised_data = np.concatenate(denoised_data, axis=0)\n",
    "    denoised_data = denoised_data.reshape(original_shape)\n",
    "    \n",
    "    print(\"Denoising complete.\")\n",
    "    return denoised_data\n",
    "     \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Ensure input data is float32\n",
    "SI_raw.data = SI_raw.data.astype(np.float32)\n",
    "\n",
    "try:\n",
    "    # Print input shape\n",
    "    print(f\"Input data shape: {SI_raw.data.shape}\")\n",
    "    \n",
    "    # Denoise the data\n",
    "    denoised_data = denoise_EELS_data(SI_raw.data, device=device)\n",
    "    \n",
    "    # Convert back to HyperSpy signal\n",
    "    SI_denoised = hs.signals.Signal1D(denoised_data)\n",
    "    \n",
    "    # Plot comparison\n",
    "    x, y = np.random.randint(0, SI_raw.data.shape[0]), np.random.randint(0, SI_raw.data.shape[1])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(SI_raw.data[x,y], label='Original', alpha=0.7)\n",
    "    plt.plot(denoised_data[x,y], label='Denoised', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.title(f'Comparison at pixel ({x}, {y})')\n",
    "    plt.show()\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    print(f\"Error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
